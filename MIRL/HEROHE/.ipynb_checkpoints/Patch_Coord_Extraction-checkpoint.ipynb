{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os, csv\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import glob\n",
    "from shutil import copyfile\n",
    "import openslide\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import points_in_poly\n",
    "from skimage import feature\n",
    "from skimage.feature import canny\n",
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from skimage.feature import canny\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/media/mak/mirlproject1'\n",
    "# ROOT_PATH = '/media/balaji/CamelyonProject/CAMELYON_DATASET'\n",
    "\n",
    "# Camelyon 2016\n",
    "train_tif_cm16_path = ROOT_PATH+'/CAMELYON16/TrainingData/normal_tumor'\n",
    "train_xml_cm16_path = ROOT_PATH+'/CAMELYON16/TrainingData/lesion_annotations'\n",
    "train_json_cm16_path = ROOT_PATH+'/CAMELYON16/TrainingData/lesion_annotations_jsons'\n",
    "train_mask_cm16_path = ROOT_PATH+'/CAMELYON16/TrainingData/lesion_masks'\n",
    "\n",
    "test_tif_cm16_path = ROOT_PATH+'/CAMELYON16/Testset/Images'\n",
    "test_xml_cm16_path = ROOT_PATH+'/CAMELYON16/Testset/lesion_annotations'\n",
    "test_json_cm16_path = ROOT_PATH+'/CAMELYON16/Testset/lesion_annotations_jsons'\n",
    "test_mask_cm16_path = ROOT_PATH+'/CAMELYON16/Testset/Backup/Masks/tif_files'\n",
    "\n",
    "# Camelyon 2017\n",
    "train_tif_cm17_path = ROOT_PATH+'/CAMELYON17/training/dataset'\n",
    "train_xml_cm17_path = ROOT_PATH+'/CAMELYON17/training/groundtruth/lesion_annotations/XML'\n",
    "train_json_cm17_path = ROOT_PATH+'/CAMELYON17/training/groundtruth/lesion_annotations/json'\n",
    "train_mask_cm17_path = ROOT_PATH+'/CAMELYON17/training/groundtruth/lesion_annotations/Mask'\n",
    "test_tif_cm17_path = ROOT_PATH+'/CAMELYON17/testing/centers/zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM16 NCRF points\n",
    "ncrf_train_hpoints = '../../data/patch_coords/hardmined_points/train_cm16_ncrf.txt'\n",
    "ncrf_valid_hpoints = '../../data/patch_coords/hardmined_points/valid_cm16_ncrf.txt'\n",
    "\n",
    "# CM_17_hardmined_points_dir = '../../data/datasetgen/DenseNet-121_UNET_CM16_NCRF/Hardmine_CM17/level_5_16/csv'\n",
    "CM_17_hardmined_points_dir = '/media/mak/mak2TB/Camelyon_17/predictions/Ensemble_CM17/CM17_Train/level_4_16/csv'\n",
    "# CV fold: 3 folds exists\n",
    "fold_no = 0\n",
    "base_path = '../../data/datasetgen'\n",
    "# base_path = '/media/balaji/CamelyonProject/CAMELYON_DATASET/Projects/Semantic_Segmentation/datasetgen'\n",
    "CM_16_Train_train_split = base_path+'/cm16_train_cross_val_splits/training_fold_{}.csv'.format(fold_no)\n",
    "CM_16_Train_valid_split = base_path+'/cm16_train_cross_val_splits/validation_fold_{}.csv'.format(fold_no)\n",
    "\n",
    "CM_16_Test_train_split = base_path+'/cm16_test_cross_val_splits/training_fold_{}.csv'.format(fold_no)\n",
    "CM_16_Test_valid_split = base_path+'/cm16_test_cross_val_splits/validation_fold_{}.csv'.format(fold_no)\n",
    "\n",
    "CM_17_Train_train_split = base_path+'/cm17_cross_val_splits/training_fold_{}.csv'.format(fold_no)\n",
    "CM_17_Train_valid_split = base_path+'/cm17_cross_val_splits/validation_fold_{}.csv'.format(fold_no)\n",
    "\n",
    "CM_17_CM_16_Train_valid_folds_path = base_path+'/cm17_cm16_train_cross_val_splits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "PATCH_LEVEL = 0\n",
    "# Output path for text files of coordinates\n",
    "out_path = '../../data/patch_coords/cm17_random_DFCN_Hardmined_patch_size_256/reference'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def ReadWholeSlideImage(image_path, level=None, RGB=True, read_image=True):\n",
    "    \"\"\"\n",
    "    # =========================\n",
    "    # Read Whole-Slide Image \n",
    "    # =========================\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wsi_obj = openslide.OpenSlide(image_path)\n",
    "        n_levels = wsi_obj.level_count\n",
    "#         print(\"Number of Levels\", n_levels)\n",
    "#         print(\"Dimensions:%s, level_dimensions:%s\"%(wsi_obj.dimensions, wsi_obj.level_dimensions))\n",
    "#         print(\"Level_downsamples:\", wsi_obj.level_downsamples)        \n",
    "#         print(\"Properties\", wsi_obj.properties)     \n",
    "        if (level is None) or (level > n_levels-1):\n",
    "            level = n_levels-1\n",
    "#             print ('Default level selected', level)\n",
    "        if read_image:\n",
    "            if RGB:\n",
    "                image_data = np.transpose(np.array(wsi_obj.read_region((0, 0),\n",
    "                                   level,\n",
    "                                   wsi_obj.level_dimensions[level]).convert('RGB')),\n",
    "                                   axes=[1, 0, 2])\n",
    "            else: \n",
    "                image_data = np.array(wsi_obj.read_region((0, 0),\n",
    "                           level,\n",
    "                           wsi_obj.level_dimensions[level]).convert('L')).T\n",
    "        else:\n",
    "            image_data = None \n",
    "#         print (image_data.shape)\n",
    "    except openslide.OpenSlideUnsupportedFormatError:\n",
    "        print('Exception: OpenSlideUnsupportedFormatError')\n",
    "        return None, None, None\n",
    "\n",
    "    return wsi_obj, image_data, level\n",
    "\n",
    "def imshow(*args,**kwargs):\n",
    "    \"\"\" Handy function to show multiple plots in on row, possibly with different cmaps and titles\n",
    "    Usage:\n",
    "    imshow(img1, title=\"myPlot\")\n",
    "    imshow(img1,img2, title=['title1','title2'])\n",
    "    imshow(img1,img2, cmap='hot')\n",
    "    imshow(img1,img2,cmap=['gray','Blues']) \"\"\"\n",
    "    cmap = kwargs.get('cmap', 'gray')\n",
    "    title= kwargs.get('title','')\n",
    "    axis_off = kwargs.get('axis_off','')\n",
    "    if len(args)==0:\n",
    "        raise ValueError(\"No images given to imshow\")\n",
    "    elif len(args)==1:\n",
    "        plt.title(title)\n",
    "        plt.imshow(args[0], interpolation='none')\n",
    "    else:\n",
    "        n=len(args)\n",
    "        if type(cmap)==str:\n",
    "            cmap = [cmap]*n\n",
    "        if type(title)==str:\n",
    "            title= [title]*n\n",
    "        plt.figure(figsize=(n*5,10))\n",
    "        for i in range(n):\n",
    "            plt.subplot(1,n,i+1)\n",
    "            plt.title(title[i])\n",
    "            plt.imshow(args[i], cmap[i])\n",
    "            if axis_off: \n",
    "              plt.axis('off')  \n",
    "    plt.show()\n",
    "    \n",
    "class Polygon(object):\n",
    "    \"\"\"\n",
    "    Polygon represented as [N, 2] array of vertices\n",
    "    \"\"\"\n",
    "    def __init__(self, name, vertices):\n",
    "        \"\"\"\n",
    "        Initialize the polygon.\n",
    "\n",
    "        Arguments:\n",
    "            name: string, name of the polygon\n",
    "            vertices: [N, 2] 2D numpy array of int\n",
    "        \"\"\"\n",
    "        self._name = name\n",
    "        self._vertices = vertices\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._name\n",
    "\n",
    "    def inside(self, coord):\n",
    "        \"\"\"\n",
    "        Determine if a given coordinate is inside the polygon or not.\n",
    "\n",
    "        Arguments:\n",
    "            coord: 2 element tuple of int, e.g. (x, y)\n",
    "\n",
    "        Returns:\n",
    "            bool, if the coord is inside the polygon.\n",
    "        \"\"\"\n",
    "        return points_in_poly([coord], self._vertices)[0]\n",
    "\n",
    "    def vertices(self):\n",
    "\n",
    "        return np.array(self._vertices)\n",
    "\n",
    "class Annotation(object):\n",
    "    \"\"\"\n",
    "    Annotation about the regions within BBOX in terms of vertices of polygons.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._bbox = []\n",
    "        self._polygons_positive = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._json_path\n",
    "\n",
    "    def from_json(self, json_path):\n",
    "        \"\"\"\n",
    "        Initialize the annotation from a json file.\n",
    "\n",
    "        Arguments:\n",
    "            json_path: string, path to the json annotation.\n",
    "        \"\"\"\n",
    "        self._json_path = json_path\n",
    "        with open(json_path) as f:\n",
    "            annotations_json = json.load(f)\n",
    "\n",
    "        for annotation in annotations_json['positive']:\n",
    "            name = annotation['name']\n",
    "            vertices = np.array(annotation['vertices'])      \n",
    "            polygon = Polygon(name, vertices)\n",
    "            if name == 'BBOX':\n",
    "                self._bbox.append(polygon)\n",
    "            else:\n",
    "                self._polygons_positive.append(polygon)\n",
    "                \n",
    "    def inside_bbox(self, coord):\n",
    "        \"\"\"\n",
    "        Determine if a given coordinate is inside the positive polygons of the annotation.\n",
    "\n",
    "        Arguments:\n",
    "            coord: 2 element tuple of int, e.g. (x, y)\n",
    "\n",
    "        Returns:\n",
    "            bool, if the coord is inside the positive/negative polygons of the\n",
    "            annotation.\n",
    "        \"\"\"\n",
    "        bboxes = copy.deepcopy(self._bbox)\n",
    "        for bbox in bboxes:\n",
    "            if bbox.inside(coord):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def bbox_vertices(self):\n",
    "        \"\"\"\n",
    "        Return the polygon represented as [N, 2] array of vertices\n",
    "\n",
    "        Arguments:\n",
    "            is_positive: bool, return positive or negative polygons.\n",
    "\n",
    "        Returns:\n",
    "            [N, 2] 2D array of int\n",
    "        \"\"\"\n",
    "        return list(map(lambda x: x.vertices(), self._bbox))\n",
    "    \n",
    "    def inside_polygons(self, coord):\n",
    "        \"\"\"\n",
    "        Determine if a given coordinate is inside the positive polygons of the annotation.\n",
    "\n",
    "        Arguments:\n",
    "            coord: 2 element tuple of int, e.g. (x, y)\n",
    "\n",
    "        Returns:\n",
    "            bool, if the coord is inside the positive/negative polygons of the\n",
    "            annotation.\n",
    "        \"\"\"\n",
    "        polygons = copy.deepcopy(self._polygons_positive)\n",
    "        \n",
    "        for polygon in polygons:\n",
    "            if polygon.inside(coord):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def polygon_vertices(self):\n",
    "        \"\"\"\n",
    "        Return the polygon represented as [N, 2] array of vertices\n",
    "\n",
    "        Arguments:\n",
    "            is_positive: bool, return positive or negative polygons.\n",
    "\n",
    "        Returns:\n",
    "            [N, 2] 2D array of int\n",
    "        \"\"\"\n",
    "        return list(map(lambda x: x.vertices(), self._polygons_positive))\n",
    "\n",
    "def getEdgeImage(image):\n",
    "    label_image = np.array(image, dtype=bool)\n",
    "    edgeImage = canny(label_image, sigma=0.0001) \n",
    "    return edgeImage\n",
    "\n",
    "def TissueMask(img_RGB, level):\n",
    "#     img_data = img_RGB.copy()    \n",
    "    morpho_kernel = np.ones((7,7),np.uint8)\n",
    "    np.place(img_RGB, img_RGB<=0, 255)\n",
    "    img_RGB = cv2.medianBlur(img_RGB, 15)\n",
    "    img_HSV = rgb2hsv(img_RGB)\n",
    "    \n",
    "    tissue_mask_S = img_HSV[:, :, 1] > threshold_otsu(img_HSV[:, :, 1])\n",
    "    tissue_mask_S_ccd = cv2.dilate(np.uint8(tissue_mask_S), morpho_kernel, iterations = 5)\n",
    "    return np.array(tissue_mask_S_ccd)\n",
    "\n",
    "\n",
    "# def TissueMask(img_RGB, level):\n",
    "#     RGB_min = 50\n",
    "#     # note the shape of img_RGB is the transpose of slide.level_dimensions\n",
    "#     img_HSV = rgb2hsv(img_RGB)\n",
    "\n",
    "#     background_R = img_RGB[:, :, 0] > threshold_otsu(img_RGB[:, :, 0])\n",
    "#     background_G = img_RGB[:, :, 1] > threshold_otsu(img_RGB[:, :, 1])\n",
    "#     background_B = img_RGB[:, :, 2] > threshold_otsu(img_RGB[:, :, 2])\n",
    "#     tissue_RGB = np.logical_not(background_R & background_G & background_B)\n",
    "#     tissue_S = img_HSV[:, :, 1] > threshold_otsu(img_HSV[:, :, 1])\n",
    "#     min_R = img_RGB[:, :, 0] > RGB_min\n",
    "#     min_G = img_RGB[:, :, 1] > RGB_min\n",
    "#     min_B = img_RGB[:, :, 2] > RGB_min\n",
    "#     tissue_mask = tissue_S & tissue_RGB & min_R & min_G & min_B\n",
    "#     return tissue_mask\n",
    "\n",
    "# def TissueMask_BIN_OTSU(img_RGB, level):\n",
    "\n",
    "#     img_HSV = cv2.cvtColor(img_RGB, cv2.COLOR_BGR2HSV)\n",
    "#     img_S = img_HSV[:, :, 1]\n",
    "#     _,tissue_mask = cv2.threshold(img_S, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#     return tissue_mask\n",
    "\n",
    "def ShuffleAndSampleFirstN(data, n=10):\n",
    "    \"\"\"\n",
    "    Sampling by shuffling the data, then get only the first n elements.\";\n",
    "    \"\"\"\n",
    "    data=copy.deepcopy(data);\n",
    "    random.shuffle(data);\n",
    "    sample=data[0:n];\n",
    "    return sample\n",
    "\n",
    "def RandomUniformSample(data, n=1000, factor=1):\n",
    "    data=copy.deepcopy(data);\n",
    "    if len(data) <= n:\n",
    "        sample_n = len(data)*factor        \n",
    "    else:\n",
    "        sample_n = n\n",
    "        \n",
    "    idxs = [];\n",
    "    while len(idxs)<sample_n:\n",
    "        rand=int(random.uniform(0, len(data)))\n",
    "        if rand in idxs:\n",
    "            pass\n",
    "        else:\n",
    "            idxs.append(rand);\n",
    "    sample=[data[i] for i in idxs];\n",
    "    return sample\n",
    "\n",
    "def merge_files(file_list, output_file_path):\n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        for fname in file_list:\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line) \n",
    "                    \n",
    "def combine_nms_files(files_dir_path, data_split_csv, output_file):\n",
    "    \"\"\"\n",
    "    Combine all the files listed in data_split_csv from \"files_dir_path\" for CM17 dataset\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    data_split_df = pd.read_csv(data_split_csv)\n",
    "    for i in range(len(data_split_df.Image_Path)):\n",
    "        file_path = os.path.join(files_dir_path, os.path.basename(data_split_df.Image_Path[i]).split('.')[0]+'_ensemble.csv')\n",
    "        files.append(file_path)\n",
    "    mask_files = []\n",
    "    for i in range(len(data_split_df.Mask_Path)):\n",
    "        if data_split_df.Mask_Path[i] !='0':\n",
    "            mask_dir = os.path.dirname(data_split_df.Mask_Path[i])\n",
    "            mask_files.append(os.path.basename(data_split_df.Mask_Path[i]))\n",
    "    image_dir = os.path.dirname(os.path.dirname(data_split_df.Image_Path[i]))            \n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for fname in files:\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    _, x_center, y_center = line.strip('\\n').split(',')[0:3]\n",
    "                    pid = os.path.basename(fname)[:18]+'.tif'\n",
    "                    pid_no = int(pid.split('_')[1])\n",
    "                    center_folder = 'center_'+str(int(pid_no//20))\n",
    "                    pid_path = os.path.join(image_dir,center_folder,pid)\n",
    "                    mask_name = pid.split('.')[0]+'_mask.tif'\n",
    "                    if mask_name in mask_files:\n",
    "                        mask_path = os.path.join(mask_dir, pid.split('.')[0]+'_mask.tif')\n",
    "                        line = pid_path+','+mask_path+','+x_center+','+y_center+'\\n'\n",
    "                    else:\n",
    "                        line = pid_path+','+str(0)+','+x_center+','+y_center+'\\n'\n",
    "                    outfile.write(line) \n",
    "                    \n",
    "                    \n",
    "def combine_text_files(files_dir_path, data_split_csv, output_file):\n",
    "    \"\"\"\n",
    "    Combine all the files listed in data_split_csv from \"files_dir_path\" for CM17 dataset\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    data_split_df = pd.read_csv(data_split_csv)\n",
    "    for i in range(len(data_split_df.Image_Path)):\n",
    "        file_path = os.path.join(files_dir_path, os.path.basename(data_split_df.Image_Path[i]).split('.')[0])\n",
    "        files.append(file_path)\n",
    "    mask_files = []\n",
    "    for i in range(len(data_split_df.Mask_Path)):\n",
    "        if data_split_df.Mask_Path[i] !='0':\n",
    "            mask_dir = os.path.dirname(data_split_df.Mask_Path[i])\n",
    "            mask_files.append(os.path.basename(data_split_df.Mask_Path[i]))\n",
    "    image_dir = os.path.dirname(os.path.dirname(data_split_df.Image_Path[i]))            \n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for fname in files:\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    pid, x_center, y_center = line.strip('\\n').split(',')[0:3]\n",
    "                    pid_no = int(pid.split('_')[1])\n",
    "                    center_folder = 'center_'+str(int(pid_no//20))\n",
    "                    pid_path = os.path.join(image_dir,center_folder,pid)\n",
    "                    mask_name = pid.split('.')[0]+'_mask.tif'\n",
    "                    if mask_name in mask_files:\n",
    "                        mask_path = os.path.join(mask_dir, pid.split('.')[0]+'_mask.tif')\n",
    "                        line = pid_path+','+mask_path+','+x_center+','+y_center+'\\n'\n",
    "                    else:\n",
    "                        line = pid_path+','+str(0)+','+x_center+','+y_center+'\\n'\n",
    "                    outfile.write(line) \n",
    "                    \n",
    "def extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode, max_normal_points=500):                    \n",
    "    '''\n",
    "    Extract Normal Patches coordinates and write to text file\n",
    "    '''\n",
    "    patch_level = PATCH_LEVEL\n",
    "    patch_size = PATCH_SIZE\n",
    "    tumor_threshold = 0\n",
    "    sampling_level = 4\n",
    "    target_file = open(os.path.join(out_path, \"{}_random_sample.txt\".format(mode)), 'a')\n",
    "    \n",
    "    if os.path.exists(mask_path):\n",
    "        mask_obj, mask_data, level = ReadWholeSlideImage(mask_path, sampling_level)\n",
    "        if sampling_level > level:\n",
    "            sampling_level = level\n",
    "        wsi_obj, img_data, level = ReadWholeSlideImage(image_path, sampling_level, read_image=True)   \n",
    "        tissue_mask = TissueMask(img_data, sampling_level)\n",
    "        sampled_normal_pixels = np.transpose(np.nonzero(tissue_mask))\n",
    "        # Perform Uniform sampling\n",
    "        sampled_normal_pixels = RandomUniformSample(sampled_normal_pixels, max_normal_points)\n",
    "        # Perform Uniform sampling\n",
    "        sampled_normal_pixels_verified = []\n",
    "        org_mag_factor = pow(2, sampling_level)                \n",
    "        for coord in sampled_normal_pixels:   \n",
    "            scoord = (int(coord[0]*org_mag_factor), int(coord[1]*org_mag_factor))\n",
    "            shifted_point = (int(scoord[0]-patch_size//2), int(scoord[1]-patch_size//2))\n",
    "            mask_patch = np.array(mask_obj.read_region(shifted_point, patch_level, (patch_size, patch_size)).convert('L'))        \n",
    "            tumor_fraction = np.count_nonzero(mask_patch)/np.prod(mask_patch.shape) \n",
    "            if tumor_fraction <= tumor_threshold:\n",
    "                slide_patch = np.array(wsi_obj.read_region(shifted_point, patch_level, (patch_size, patch_size)).convert('RGB'))\n",
    "                if np.sum(slide_patch) >= 1:\n",
    "                    sampled_normal_pixels_verified.append(scoord)\n",
    "#                     imshow(slide_patch, mask_patch)\n",
    "\n",
    "    else:\n",
    "        mask_path = '0'\n",
    "        wsi_obj, img_data, level = ReadWholeSlideImage(image_path, sampling_level, read_image=True)   \n",
    "        if sampling_level > level:\n",
    "            sampling_level = level        \n",
    "        tissue_mask = TissueMask(img_data, sampling_level)        \n",
    "        sampled_normal_pixels = np.transpose(np.nonzero(tissue_mask))\n",
    "        # Perform Uniform sampling\n",
    "        sampled_normal_pixels = RandomUniformSample(sampled_normal_pixels, max_normal_points)\n",
    "        # Perform Uniform sampling\n",
    "        sampled_normal_pixels_verified = []\n",
    "        org_mag_factor = pow(2, sampling_level)    \n",
    "        for coord in sampled_normal_pixels:   \n",
    "            scoord = (int(coord[0]*org_mag_factor), int(coord[1]*org_mag_factor))\n",
    "            shifted_point = (int(scoord[0]-patch_size//2), int(scoord[1]-patch_size//2))            \n",
    "            slide_patch = np.array(wsi_obj.read_region(shifted_point, patch_level, (patch_size, patch_size)).convert('RGB'))\n",
    "            if np.sum(slide_patch) >= 1:\n",
    "                sampled_normal_pixels_verified.append(scoord)\n",
    "#                 imshow(slide_patch)            \n",
    "    print ('Normal Pixels:', len(sampled_normal_pixels_verified))    \n",
    "    for tpoint in sampled_normal_pixels_verified:\n",
    "        target_file.write(image_path +','+mask_path +','+ str(tpoint[0]) + ',' + str(tpoint[1])+',' + str(0))        \n",
    "        target_file.write(\"\\n\")\n",
    "    target_file.close()    \n",
    "    return(len(sampled_normal_pixels_verified))                    \n",
    "                  \n",
    "def extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode, max_tumor_points=1000):\n",
    "    '''\n",
    "    Extract Patches coordinates and write to text file\n",
    "    '''\n",
    "    patch_size = PATCH_SIZE\n",
    "    patch_level = PATCH_LEVEL\n",
    "    sampling_level = 4\n",
    "    tumor_threshold = 0.1\n",
    "    \n",
    "    target_file = open(os.path.join(out_path, \"{}_random_sample.txt\".format(mode)), 'a')\n",
    "    mask_obj, mask_data, level = ReadWholeSlideImage(mask_path, sampling_level, RGB=False, read_image=True)\n",
    "    if sampling_level > level:\n",
    "        sampling_level = level\n",
    "    org_mag_factor = pow(2, sampling_level)\n",
    "    tumor_pixels = list(np.transpose(np.nonzero(mask_data)))\n",
    "    tumor_pixels = RandomUniformSample(tumor_pixels, max_tumor_points) \n",
    "    anno = Annotation()\n",
    "    anno.from_json(json_path)  \n",
    "    anno_vertices_list = list(anno.polygon_vertices())\n",
    "    anno_vertices_flat_list = [item for sublist in anno_vertices_list for item in sublist]\n",
    "    sampled_anno_vertices_flat_list = RandomUniformSample(anno_vertices_flat_list, max_tumor_points)        \n",
    "    \n",
    "    # Perform Uniform sampling    \n",
    "    scaled_tumor_pixels = []\n",
    "    for coord in list(tumor_pixels):    \n",
    "        scoord = (int(coord[0]*org_mag_factor), int(coord[1]*org_mag_factor))   \n",
    "        scaled_tumor_pixels.append(scoord)                   \n",
    "    scaled_tumor_pixels.extend(sampled_anno_vertices_flat_list)    \n",
    "    scaled_tumor_pixels_verified = []\n",
    "    \n",
    "    for scoord in scaled_tumor_pixels:\n",
    "        scaled_shifted_point = (scoord[0]-patch_size//2, scoord[1]-patch_size//2)\n",
    "        wsi_obj, _, level = ReadWholeSlideImage(image_path, sampling_level, RGB=True, read_image=False)\n",
    "        slide_patch = np.array(wsi_obj.read_region(scaled_shifted_point, patch_level, (patch_size, patch_size)).convert('RGB'))\n",
    "        mask_patch = np.array(mask_obj.read_region(scaled_shifted_point, patch_level, (patch_size, patch_size)).convert('L'))\n",
    "        tumor_fraction = np.count_nonzero(mask_patch)/np.prod(mask_patch.shape) \n",
    "        if tumor_fraction >= tumor_threshold:\n",
    "            if np.sum(slide_patch) >= 1:\n",
    "                scaled_tumor_pixels_verified.append(scoord)\n",
    "#                 imshow(slide_patch, mask_patch)        \n",
    "    print ('Number of Tumor Pixels', len(scaled_tumor_pixels_verified))\n",
    "    for tpoint in scaled_tumor_pixels_verified:\n",
    "        target_file.write(image_path +','+mask_path +','+ str(tpoint[0]) + ',' + str(tpoint[1])+',' + str(np.around(tumor_fraction, decimals=1)))        \n",
    "        target_file.write(\"\\n\")\n",
    "\n",
    "    target_file.close()\n",
    "    return(len(scaled_tumor_pixels))\n",
    "\n",
    "def split_df(df, column, save_dir, mode,threshold=0):\n",
    "    df_tumor = df.loc[df[column]>threshold]\n",
    "    df_normal = df.loc[df[column]==threshold]\n",
    "    df_tumor.to_csv(os.path.join(save_dir,'{}_tumor.txt'.format(mode)), header=False, index=False)\n",
    "    df_normal.to_csv(os.path.join(save_dir,'{}_normal.txt'.format(mode)), header=False, index=False)    \n",
    "    return(df_tumor, df_normal)\n",
    "\n",
    "def get_tumor_fraction(mask_image):\n",
    "    fraction = np.count_nonzero(mask_image)/np.prod(mask_image.shape)\n",
    "    return fraction\n",
    "                                   \n",
    "def add_tumor_fraction(coord_file_path, out_file_name, patch_size=(256,256)):\n",
    "    tumor_samples = 0\n",
    "    fi = open(coord_file_path)\n",
    "    fo = open(os.path.dirname(coord_file_path)+'/'+ out_file_name, 'a')  \n",
    "    for line in fi:\n",
    "        if len(line.strip('\\n').split(',')) <= 4:            \n",
    "            image_path, mask_path, x_center, y_center = line.strip('\\n').split(',')[0:4]            \n",
    "            if os.path.exists(mask_path):                       \n",
    "                x_top_left = int(int(x_center) - patch_size[0] / 2)\n",
    "                y_top_left = int(int(y_center) - patch_size[1] / 2)     \n",
    "                mask_obj = openslide.OpenSlide(mask_path)                                   \n",
    "                mask_data = np.array(mask_obj.read_region((x_top_left, y_top_left),\n",
    "                                   0,\n",
    "                                   patch_size).convert('L'))                                   \n",
    "                tumor_fraction = get_tumor_fraction(mask_data)\n",
    "                if tumor_fraction > 0.0:\n",
    "                    tumor_samples += 1\n",
    "    #                 image_opslide = openslide.OpenSlide(image_path)\n",
    "    #                 image_data = image_opslide.read_region(\n",
    "    #                     (x_top_left, y_top_left), 0,\n",
    "    #                     patch_size).convert('RGB')\n",
    "    #                 print (mask_path, tumor_fraction)\n",
    "    #                 imshow(image_data, mask_data)\n",
    "            else:\n",
    "                mask_path ='0'\n",
    "                tumor_fraction = 0\n",
    "        else:\n",
    "            image_path, mask_path, x_center, y_center, tumor_fraction = line.strip('\\n').split(',')[0:5] \n",
    "            tumor_fraction = float(tumor_fraction)+0.01\n",
    "        fo.write(image_path +','+mask_path +','+x_center+','+y_center+','+str(np.around(tumor_fraction, decimals=1)))        \n",
    "        fo.write(\"\\n\")\n",
    "    fo.close()\n",
    "    fi.close()\n",
    "    return tumor_samples\n",
    "\n",
    "def generate_folds(wsi_dict, fold_path, save_path, mode):\n",
    "    combined_dataset = pd.read_csv(fold_path)\n",
    "    pids =[]\n",
    "    mask_ids = []\n",
    "    xs = []\n",
    "    ys = []\n",
    "    fracs = []\n",
    "    for pid, maskid in zip(combined_dataset['Image_Path'].values, combined_dataset['Mask_Path'].values):\n",
    "        pid_ = pid.split('/')[-1]\n",
    "        info = np.array(wsi_dict[pid_])\n",
    "        if len(info):\n",
    "            pids.extend([pid]*info.shape[0])\n",
    "            mask_ids.extend([maskid]*info.shape[0])\n",
    "            xs.extend(info[:, 1])\n",
    "            ys.extend(info[:, 2])\n",
    "            fracs.extend(np.array(info[:, 3], dtype='float'))\n",
    "    df = pd.DataFrame()\n",
    "    df['pid']  = pids\n",
    "    df['mask'] = mask_ids\n",
    "    df['x']  = xs\n",
    "    df['y']  = ys\n",
    "    df['tf'] = fracs\n",
    "    df_tumor, df_normal = split_df(df, 'tf', save_path, mode)\n",
    "    print (len(df_tumor), len(df_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = 0\n",
    "valid_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM17 Train Random Sample Coordinates\n",
    "train_dest_path_cm17 = os.path.join(out_path, 'train_CM17_Train_random_sample.txt')\n",
    "valid_dest_path_cm17 = os.path.join(out_path, 'valid_CM17_Train_random_sample.txt')\n",
    "\n",
    "if not os.path.exists(train_dest_path_cm17):\n",
    "    mode = 'train_CM17_Train'\n",
    "    train_split_df = pd.read_csv(CM_17_Train_train_split)\n",
    "    for index, row in train_split_df.iterrows():\n",
    "        image_path = row['Image_Path']\n",
    "        image_file = os.path.basename(image_path).split('.')[0]\n",
    "        mask_path = os.path.join(train_mask_cm17_path, image_file +'_mask.tif')\n",
    "        json_path = os.path.join(train_json_cm17_path, image_file +'.json')\n",
    "        train_count+=extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode, max_normal_points=500)    \n",
    "        if os.path.exists(mask_path):\n",
    "            train_count+=extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode, max_tumor_points=1500)\n",
    "    print ('Points sampled:', train_count)\n",
    "\n",
    "if not os.path.exists(valid_dest_path_cm17):    \n",
    "    mode = 'valid_CM17_Train'    \n",
    "    valid_split_df = pd.read_csv(CM_17_Train_valid_split)\n",
    "    for index, row in valid_split_df.iterrows():\n",
    "        image_path = row['Image_Path']\n",
    "        image_file = os.path.basename(image_path).split('.')[0]  \n",
    "        mask_path = os.path.join(train_mask_cm17_path, image_file+'_mask.tif')\n",
    "        json_path = os.path.join(train_json_cm17_path, image_file +'.json') \n",
    "        valid_count+=extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode, max_normal_points=500)\n",
    "        if os.path.exists(mask_path):    \n",
    "    #         print (mask_path)\n",
    "            valid_count+=extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode, max_tumor_points=1500)\n",
    "    print ('Points sampled:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM16 Train Random Sample Coordinates\n",
    "train_dest_path_cm16_train = os.path.join(out_path, 'train_CM16_Train_random_sample.txt')\n",
    "valid_dest_path_cm16_train = os.path.join(out_path, 'valid_CM16_Train_random_sample.txt')\n",
    "\n",
    "if not os.path.exists(train_dest_path_cm16_train):\n",
    "    mode = 'train_CM16_Train'\n",
    "    train_split_df = pd.read_csv(CM_16_Train_train_split)\n",
    "    for index, row in train_split_df.iterrows():\n",
    "        image_path = row['Image_Path']\n",
    "        image_file = os.path.basename(image_path).split('.')[0]\n",
    "        mask_path = os.path.join(train_mask_cm16_path, image_file +'_Mask.tif')\n",
    "        json_path = os.path.join(train_json_cm16_path, image_file.lower() +'.json')\n",
    "        train_count+=extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "        if os.path.exists(mask_path):\n",
    "            train_count+=extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "    print ('Points sampled:', train_count)\n",
    "\n",
    "if not os.path.exists(valid_dest_path_cm16_train):    \n",
    "    mode = 'valid_CM16_Train'    \n",
    "    valid_split_df = pd.read_csv(CM_16_Train_valid_split)\n",
    "    for index, row in valid_split_df.iterrows():\n",
    "        image_path = row['Image_Path']\n",
    "        image_file = os.path.basename(image_path).split('.')[0]\n",
    "        mask_path = os.path.join(train_mask_cm16_path, image_file+'_Mask.tif')\n",
    "        json_path = os.path.join(train_json_cm16_path, image_file.lower() +'.json') \n",
    "        valid_count+=extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "        if os.path.exists(mask_path):    \n",
    "    #         print (mask_path)\n",
    "            valid_count+=extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "    print ('Points sampled:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CM16 Test Random Sample Coordinates\n",
    "# train_dest_path_cm16_test = os.path.join(out_path, 'train_CM16_Test_random_sample.txt')\n",
    "# valid_dest_path_cm16_test = os.path.join(out_path, 'valid_CM16_Test_random_sample.txt')\n",
    "\n",
    "# if not os.path.exists(train_dest_path_cm16_test):\n",
    "#     mode = 'train_CM16_Test'\n",
    "#     train_split_df = pd.read_csv(CM_16_Test_train_split)\n",
    "#     for index, row in train_split_df.iterrows():\n",
    "#         image_path = row['Image_Path']\n",
    "#         image_file = os.path.basename(image_path).split('.')[0]\n",
    "#         mask_path = os.path.join(test_mask_cm16_path, image_file +'_Mask.tif')\n",
    "#         json_path = os.path.join(test_json_cm16_path, image_file.lower() +'.json')\n",
    "#         train_count+=extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "#         if os.path.exists(mask_path):\n",
    "#             train_count+=extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "#     print ('Points sampled:', train_count)\n",
    "\n",
    "# if not os.path.exists(valid_dest_path_cm16_test):    \n",
    "#     mode = 'valid_CM16_Test'    \n",
    "#     valid_split_df = pd.read_csv(CM_16_Test_valid_split)\n",
    "#     for index, row in valid_split_df.iterrows():\n",
    "#         image_path = row['Image_Path']\n",
    "#         image_file = os.path.basename(image_path).split('.')[0]\n",
    "#         mask_path = os.path.join(test_mask_cm16_path, image_file+'_Mask.tif')\n",
    "#         json_path = os.path.join(test_json_cm16_path, image_file.lower() +'.json') \n",
    "#         valid_count+=extract_normal_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)    \n",
    "#         if os.path.exists(mask_path):    \n",
    "#             valid_count+=extract_tumor_patches_from_wsi(image_path, mask_path, json_path, out_path, mode)\n",
    "#     print ('Points sampled:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hardmined points from CM17 training dataset from CM16 trained model\n",
    "# Hardmined from CM16 training on CM17 training dataset with annotation\n",
    "cm17_train_hpoints = os.path.join(out_path, 'train_CM17_Hardmined_DFCN_Model.txt')\n",
    "cm17_valid_hpoints = os.path.join(out_path, 'valid_CM17_Hardmined_DFCN_Model.txt')\n",
    "\n",
    "if not os.path.exists(cm17_train_hpoints):\n",
    "    combine_nms_files(CM_17_hardmined_points_dir, CM_17_Train_train_split, cm17_train_hpoints)\n",
    "train_count+= sum(1 for line in open(cm17_train_hpoints))\n",
    "print ('Points sampled:', train_count)\n",
    "\n",
    "if not os.path.exists(cm17_valid_hpoints):\n",
    "    combine_nms_files(CM_17_hardmined_points_dir, CM_17_Train_valid_split, cm17_valid_hpoints)\n",
    "valid_count+= sum(1 for line in open(cm17_valid_hpoints))\n",
    "print ('Points sampled:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CM16 NCRF coordinates\n",
    "# train_dest_path_cm16_ncrf = os.path.join(out_path, 'train_CM16_Train_NCRF.txt')\n",
    "# valid_dest_path_cm16_ncrf = os.path.join(out_path, 'valid_CM16_Train_NCRF.txt')\n",
    "\n",
    "# ncrf_patient_dict = defaultdict(list)\n",
    "# with open(ncrf_train_hpoints) as infile:\n",
    "#     for line in infile:\n",
    "#         pid, x_center, y_center = line.strip('\\n').split(',')[0:3]\n",
    "#         ncrf_patient_dict[pid].append([x_center, y_center])\n",
    "\n",
    "# with open(ncrf_valid_hpoints) as infile:\n",
    "#     for line in infile:\n",
    "#         pid, x_center, y_center = line.strip('\\n').split(',')[0:3]\n",
    "#         ncrf_patient_dict[pid].append([x_center, y_center])\n",
    "\n",
    "# if not os.path.exists(train_dest_path_cm16_ncrf):        \n",
    "#     mode = 'train_CM16_Train_NCRF'\n",
    "#     train_split_df = pd.read_csv(CM_16_Train_train_split)\n",
    "#     for index, row in train_split_df.iterrows():\n",
    "#         image_path = row['Image_Path']\n",
    "#         image_file = os.path.basename(image_path).split('.')[0]\n",
    "#         if len(ncrf_patient_dict[image_file])!=0:\n",
    "#             target_file = open(os.path.join(out_path, \"{}.txt\".format(mode)), 'a')\n",
    "#             mask_path = os.path.join(train_mask_cm16_path, image_file +'_Mask.tif')\n",
    "#             if not os.path.exists(mask_path):\n",
    "#                 mask_path = str(0)\n",
    "#             for tpoint in ncrf_patient_dict[image_file]:\n",
    "#                 target_file.write(image_path +','+mask_path +','+ str(tpoint[0]) + ',' + str(tpoint[1]))        \n",
    "#                 target_file.write(\"\\n\")\n",
    "#     train_count+= sum(1 for line in open(os.path.join(out_path, \"{}.txt\".format(mode))))\n",
    "#     print ('Points sampled:', train_count)        \n",
    "\n",
    "# if not os.path.exists(valid_dest_path_cm16_ncrf):        \n",
    "#     mode = 'valid_CM16_Train_NCRF'    \n",
    "#     valid_split_df = pd.read_csv(CM_16_Train_valid_split)\n",
    "#     for index, row in valid_split_df.iterrows():\n",
    "#         image_path = row['Image_Path']\n",
    "#         image_file = os.path.basename(image_path).split('.')[0]\n",
    "#         if len(ncrf_patient_dict[image_file])!=0:\n",
    "#             target_file = open(os.path.join(out_path, \"{}.txt\".format(mode)), 'a')\n",
    "#             mask_path = os.path.join(train_mask_cm16_path, image_file +'_Mask.tif')\n",
    "#             if not os.path.exists(mask_path):\n",
    "#                 mask_path = str(0)\n",
    "#             for tpoint in ncrf_patient_dict[image_file]:\n",
    "#                 target_file.write(image_path +','+mask_path +','+ str(tpoint[0]) + ',' + str(tpoint[1]))                    \n",
    "#                 target_file.write(\"\\n\")\n",
    "#     valid_count+= sum(1 for line in open(os.path.join(out_path, \"{}.txt\".format(mode))))\n",
    "#     print ('Points sampled:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all text files:\n",
    "train_coord_file_list = glob.glob(out_path+'/train_*')\n",
    "valid_coord_file_list = glob.glob(out_path+'/valid_*')\n",
    "combined_train_path = os.path.join(out_path, 'train.txt')\n",
    "combined_valid_path = os.path.join(out_path, 'valid.txt')\n",
    "\n",
    "train_count = 0\n",
    "valid_count = 0\n",
    "if not os.path.exists(combined_train_path):\n",
    "    merge_files(train_coord_file_list, combined_train_path)\n",
    "if not os.path.exists(combined_valid_path):    \n",
    "    merge_files(valid_coord_file_list, combined_valid_path)\n",
    "train_count+= sum(1 for line in open(combined_train_path))\n",
    "print ('Points sampled:', train_count)\n",
    "valid_count+= sum(1 for line in open(combined_valid_path))\n",
    "print ('Points sampled:', valid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dest_path_tf = os.path.join(out_path, 'tf_train.txt')\n",
    "valid_dest_path_tf = os.path.join(out_path, 'tf_valid.txt')\n",
    "\n",
    "if not os.path.exists(train_dest_path_tf):\n",
    "    train_tumor_count = add_tumor_fraction(combined_train_path, 'tf_train.txt')\n",
    "    print ('Train Stats:', 'Tumor_samples:', train_tumor_count, 'Normal_samples:', (train_count - train_tumor_count))\n",
    "\n",
    "if not os.path.exists(valid_dest_path_tf):\n",
    "    valid_tumor_count = add_tumor_fraction(combined_valid_path, 'tf_valid.txt')\n",
    "    print ('Valid Stats:', 'Tumor_samples:', valid_tumor_count, 'Normal_samples:', (valid_count - valid_tumor_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CM17 folds data only\n",
    "# CM_17_Train_valid_folds_path = base_path+'/cm17_cross_val_splits'\n",
    "\n",
    "# folds = [0, 1, 2]\n",
    "# wsi_dict = defaultdict(list)\n",
    "# with open(train_dest_path_tf) as infile:\n",
    "#     for line in infile:\n",
    "#         image_path, mask_path, x_center, y_center, tf = line.strip('\\n').split(',')[0:5]\n",
    "#         pid = os.path.basename(image_path)\n",
    "#         mask_name = os.path.basename(mask_path)            \n",
    "#         wsi_dict[pid].append([mask_name, x_center, y_center, tf])\n",
    "\n",
    "# with open(valid_dest_path_tf) as infile:\n",
    "#     for line in infile:\n",
    "#         image_path, mask_path, x_center, y_center, tf = line.strip('\\n').split(',')[0:5]\n",
    "#         pid = os.path.basename(image_path)\n",
    "#         mask_name = os.path.basename(mask_path)            \n",
    "#         wsi_dict[pid].append([mask_name, x_center, y_center, tf])\n",
    "        \n",
    "# for fold_no in folds:\n",
    "#     train_fold = os.path.join(CM_17_Train_valid_folds_path, 'training_fold_{}.csv'.format(fold_no))\n",
    "#     valid_fold = os.path.join(CM_17_Train_valid_folds_path, 'validation_fold_{}.csv'.format(fold_no))   \n",
    "#     fold_folder_save_path = os.path.dirname(out_path)+'/fold_{}'.format(fold_no)    \n",
    "#     if not os.path.exists(fold_folder_save_path):\n",
    "#         os.makedirs(fold_folder_save_path)\n",
    "#     generate_folds(wsi_dict, train_fold, fold_folder_save_path, 'train')\n",
    "#     generate_folds(wsi_dict, valid_fold, fold_folder_save_path, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [0, 1, 2]\n",
    "wsi_dict = defaultdict(list)\n",
    "with open(train_dest_path_tf) as infile:\n",
    "    for line in infile:\n",
    "        image_path, mask_path, x_center, y_center, tf = line.strip('\\n').split(',')[0:5]\n",
    "        pid = os.path.basename(image_path)\n",
    "        mask_name = os.path.basename(mask_path)            \n",
    "        wsi_dict[pid].append([mask_name, x_center, y_center, tf])\n",
    "\n",
    "with open(valid_dest_path_tf) as infile:\n",
    "    for line in infile:\n",
    "        image_path, mask_path, x_center, y_center, tf = line.strip('\\n').split(',')[0:5]\n",
    "        pid = os.path.basename(image_path)\n",
    "        mask_name = os.path.basename(mask_path)            \n",
    "        wsi_dict[pid].append([mask_name, x_center, y_center, tf])\n",
    "        \n",
    "for fold_no in folds:\n",
    "    train_fold = os.path.join(CM_17_CM_16_Train_valid_folds_path, 'training_fold_{}.csv'.format(fold_no))\n",
    "    valid_fold = os.path.join(CM_17_CM_16_Train_valid_folds_path, 'validation_fold_{}.csv'.format(fold_no))   \n",
    "    fold_folder_save_path = os.path.dirname(out_path)+'/fold_{}'.format(fold_no)    \n",
    "    if not os.path.exists(fold_folder_save_path):\n",
    "        os.makedirs(fold_folder_save_path)\n",
    "    generate_folds(wsi_dict, train_fold, fold_folder_save_path, 'train')\n",
    "    generate_folds(wsi_dict, valid_fold, fold_folder_save_path, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(coord_file_path, patch_size=(256,256)):\n",
    "    tumor_samples = 0\n",
    "    fi = open(coord_file_path)\n",
    "    for i, line in enumerate(fi):\n",
    "        if not i%1000:\n",
    "            print(i)\n",
    "            image_path, mask_path, x_center, y_center = line.strip('\\n').split(',')[0:4]\n",
    "            x_top_left = int(int(x_center) - patch_size[0] / 2)\n",
    "            y_top_left = int(int(y_center) - patch_size[1] / 2)            \n",
    "            image_opslide = openslide.OpenSlide(image_path)\n",
    "            image_data = image_opslide.read_region(\n",
    "                (x_top_left, y_top_left), 0,\n",
    "                patch_size).convert('RGB')        \n",
    "            if mask_path != '0':                       \n",
    "                x_top_left = int(int(x_center) - patch_size[0] / 2)\n",
    "                y_top_left = int(int(y_center) - patch_size[1] / 2)            \n",
    "                mask_obj = openslide.OpenSlide(mask_path)                                   \n",
    "                mask_data = np.array(mask_obj.read_region((x_top_left, y_top_left),\n",
    "                                   0,\n",
    "                                   patch_size).convert('L'))*255\n",
    "                mask_data[0,0]=0\n",
    "                mask_data \n",
    "                fraction = np.count_nonzero(mask_data)/np.prod(mask_data.shape)\n",
    "#                 if fraction > 0.0:\n",
    "#                     imshow(image_data, mask_data)                   \n",
    "            else:\n",
    "                mask_data = np.zeros_like(image_data)\n",
    "            imshow(image_data, mask_data)\n",
    "    fi.close()\n",
    "\n",
    "train_tumor = os.path.join(os.path.dirname(out_path), 'fold_0/train_tumor.txt')\n",
    "train_normal = os.path.join(os.path.dirname(out_path), 'fold_0/train_normal.txt')\n",
    "valid_tumor = os.path.join(os.path.dirname(out_path), 'fold_0/valid_tumor.txt')\n",
    "valid_normal = os.path.join(os.path.dirname(out_path), 'fold_0/valid_normal.txt')\n",
    "\n",
    "# visualize(train_tumor) \n",
    "# visualize(train_normal) \n",
    "# visualize(valid_tumor) \n",
    "# visualize(valid_normal)\n",
    "# visualize('/media/mak/mak2TB/Camelyon_17/data/patch_coords/cm17_random_DFCN_Hardmined_patch_size_256/reference/train_CM17_Hardmined_DFCN_Model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
